2019-07-16
部署到docker上后发现新浪的api返回403，目前判定为反爬。使用requests也不行，在别的机器上就可以，发现可以用代理来解决。
而且应该只需要访问api时添加代理，访问新闻网页应该不需要，因为new.sina.com.cn的robots.txt没有反对这个。这样可以减少代理压力。
不过很奇怪，以前在学校里用自己的电脑爬了很多次都没出现反爬啊，docker上我没运行过几次就没反爬了，而且过了几天试还是403。
to-do list
看新闻网页是否需要代理（已解决，不需要）
添加代理代码（已解决）
把代理池再修复一下，之前部署在docker上的似乎出问题了。（已解决）
修改网易的爬虫，因为会把在p标签下的style标签下的内容也爬下来，其余网站暂时没有发现类似情况（已解决）
腾讯有些动态页面的爬取用了跳转链接，但是似乎出了问题，需要解决

2019-07-23
解决了代理池问题，原因是爬取代理网站的其中一个爬虫出错，导致代理池无法继续运作
网易style标签问题也解决了，解决方法：response.xpath('//div[@id="endText"]//p[not(style)]//text()').extract()
to-do list
增强代理池的健壮性，不要一出错就不能继续运行，同时尝试增加一些新的代理网站以及有些代理网站有反爬措施（暂时用定时重启代理池容器来解决）
网易api会返回一些404网站，应该是被删除的文章，尝试将这些404网站URL也加入到redis中，避免再次爬取（已解决，新建了一个downloader middleware，404和403网站会保存到redis中，同时spider middleware也会做出反应）
爬虫会不会存在卡住的情况，比如我用代理有时会耗很长时间，这个可能最后能结束，但是万一出现卡住的情况我要怎么知道？因为我是用crontab来定时任务，是否可以通过crontab定时任务失败发出信息来解决？

2019-07-24
爬新浪时的确会存在卡住的现象，暂不清楚原因，需要解决。

2019-07-25
ip66代理网站会根据cookie反爬，看看scrapy有没有保存cookie等功能
考虑给sina加上ua等请求头